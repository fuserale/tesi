 %  reach 99.24% on MNIST. 
 %  Training finish after about 446 iteration , (37 epocs) can be reduces with some tweaks

 %%%%%%%%%%%%%%%%%%%%%  input settings  %%%%%%%%%%%%%%%%%%
 
 	net.hyperParam.sizeFmInput = [28 28]; 	% size of input feature map
 	net.hyperParam.numFmInput  = 1;        	% number of feature map of the input
 
 %%%%%%%%%%%%%%%%%%%%%  Layers specification %%%%%%%%%%%%%%%%%%
 
 	net.layers{end+1}.properties = struct('type',2,'numFm',7  ,'kernel',5,'pad',2);
 	net.layers{end+1}.properties = struct('type',2,'numFm',17 ,'kernel',13);
 	net.layers{end+1}.properties = struct('type',1,'numFm',127);
 	net.layers{end+1}.properties = struct('type',1,'numFm',10);
 
 %%%%%%%%%%%%%%%%%%%%%  Hyper params - training %%%%%%%%%%%%%%%%%%
 
 	net.hyperParam.trainLoopCount = 5000;		%on how many images to train before evaluating the network
 	net.hyperParam.testImageNum   = 10000;   	% after each loop, on how many images to evaluate network performance
 	net.hyperParam.ni_initial     = 0.05;		% ni to start training process
 	net.hyperParam.ni_final       = 0.00001;	% final ni to stop the training process
 
 
