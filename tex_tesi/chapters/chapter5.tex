% !TEX root = ../main.tex

% ---------------------------------------------------------------
% Automatic generation of a self-adaptive TLM model
% ---------------------------------------------------------------

\chapter[Apprendimento non supervisionato]{Apprendimento non supervisionato per l'identificazione di contensti di FoG}\label{chap5:Automatic}
I lavori che sono stati svolti e presentati nel capitolo \ref{chap2:related} sul Freezing Of Gait sono basati su approcci di classificazione ossia, come spiegato nel capitolo \ref{chap3:background}, allenano un algoritmo con dei dataset di training nel quale le etichette di ogni istante vengono fornite dalla supervisione di un dottore o fisioterapista e poi, tale algoritmo allenato, viene testato su dei nuovi dati al fine di rilevare i contesti di FoG. Il lavoro che viene presentato in questo capitolo, invece, usa le etichette fornite dal dataset solo come confronto ai risultati forniti dagli algoritmi di clustering. Quest'ultimi, infatti, una volta forniti i dati o feature (proprietà) su cui voglia applicarli, restituiscono, per ogni osservazione(nel nostro caso riga del dataset), un'etichetta che indica a quale contesto è stato assegnato ogni dato, se di FoG, non-FoG o Pre-FoG.\\
Innanzitutto verrà fornita una descrizione del dataset utilizzato e di come è stato modificato per le nostre esigenze. Verranno poi descritti i metodi utilizzati dall'approccio scelto e viene fornito il codice implementativo. Tutte lo sviluppo è stato effettuato tramite software Matlab \footnote{https://it.mathworks.com/products/matlab.html}.
\section{Dataset}
L'approccio che andiamo a proporre è stato testato sul dataset DAPHNET\footnote{www.wearable.ethz.ch/resources/Dataset}, il quale contiene dati collezionati da 10 pazienti parkinsoniani, dei quali 8 presentano contesti di FoG, mentre 2 di loro non ne presentano. I dati sono stati registrati usando 3 accelerometri 3D attaccati alla caviglia, al ginocchio e nella zona lombare del paziente, usando una frequenza di campionamento di 64 Hz, ossia vengono raccolti 64 campioni ogni secondo.\\
I soggetti hanno completato sessioni da 20-30 minuti ciascuno, consistenti di 3 fasi di camminata:
\begin{enumerate}
	\item Camminata avanti ed indietro lungo una linea retta, con delle rotazioni di 180 gradi;
	\item Camminata casuale con una serie di fermate volontarie e rotazioni di 360 gradi;
	\item Camminata che simula attività di vita quotidiana, tra le quali entrare in stanze ed uscirne, camminare nella cucina, prendersi un bicchiere d'acqua e tornare al punto di partenza.
\end{enumerate}
Le prestazioni motorie variano molto tra i pazienti. Mentre alcuni soggetti hanno mantenuto una camminata regolare durante gli episodi di non FoG, altri hanno camminato molto lentamente ed in modo instabile. L'intero dataset contiene in totale 237 episodi di FoG; la durata di ognuno di essi è tra i 0.5s ed i 40.5s. Il 50\% degli episodi di FoG è durato meno di 5.4s ed il 93.2\% è più corto di 20s. Gli episodi di FoG sono stati identificati da fisioterapisti usando registrazioni video sincronizzate. L'inizio di un episodio di FoG è stato definito come il punto dove la sequenza normale di camminata è stata interrotta, mentre la fine del FoG è stata definita come il momento in cui tale sequenza riprende.\\
Per il lavoro svolto nella tesi, oltre alle etichette date dai dottori nei casi di non FoG e FoG, abbiamo introdotto nei dati una nuova label, che indica il momento che noi indichiamo come pre-FoG, per cui tutti i campioni precedenti ad un'occorrenza di FoG sono stati etichettati con questa nuova label. Quindi ci ritroviamo con 3 label diverse invece di 2 (tutti i lavori in letteratura rientrano nell'ultimo caso): l'etichetta 1 indica un No-FoG, la label 2 indica un FoG, l'etichetta 3 indica invece un pre-FoG.
\section{Approccio basato su Feature Statistiche}
I dati raccolti dagli accelerometri, se presi in forma grezza, hanno poca potenza espressiva, ossia non riescono a fornire molte informazioni su ciò che stiamo cercando (contesti di FoG), quindi si rende necessaria una rimodellazione di tali dati. Il primo approccio che è stato preso in considerazione è basato sul calcolo di feature ( o proprietà) basate su grandezze che provengono dalla matematica statistica. Il flusso di tale approccio è:
\begin{enumerate}
	\item Pre-processamento dei dati degli accelerometri, al fine di eliminare il rumore presente ed identificare eventuali punti di outline, ossia campioni che non presentano affinità col resto dei dati poiché dovuti a movimenti non consoni;
	\item Finestramento dei dati in base ad intervalli variabili al fine di calcolare le feature, dove ogni intervallo presenta una certa sovrapposizione con l'intervallo precedente;
	\item Calcolo effettivo delle feature statistiche;
	\item Applicazione degli algoritmi di clustering;
	\item Calcolo di metriche che indicano quanto bene gli algoritmi di clustering hanno lavorato in relazione alle label fornite dal dataset.
\end{enumerate}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{images/flusso_feature.png}
	\caption{Schema generale di calcolo delle feature statistiche}
	\label{Flusso Feature}
\end{figure}
\subsection{Pre-processamento dei dati}
Gli accelerometri sono dispositivi che misurano le vibrazioni o l'accelerazione del movimento di una struttura. La forza generata dalle vibrazioni o una variazione del movimento (accelerazione) fa in modo che la massa "comprima" il materiale piezoelettrico, che genera una carica elettrica proporzionale alla forza esercitata su di esso. Dato che la carica è proporzionale alla forza e che la massa è una costante, la carica è proporzionale anche all'accelerazione. Come tutti i dispositivi che misurano delle grandezze presentano dell'incertezza strumentale che può portare ad avere rumore, ossia un segnale non desiderato, di origine naturale o artificiale, che si sovrappone all'informazione degli accelerometri stessi. QUesto rumore porta ad avere dei punti definiti outlier, ossia campioni che non presentano affinità col resto dei dati poiché dovuti a movimenti non consoni.\\
Al fine di rimuovere tali punti, che altererebbero in modo negativo il calcolo delle nostre feature, si rende necessario rimuoverli dal nostro dataset. Per identificarli, è stato implementato un filtro passa-alto che eliminano tutte le frequenze inferiori a 0.5Hz, le quali non appartengono al normale movimento umano ma indicano appunto la presenza di rumore, come evidenziato in \cite{21}. L'implementazione del filtro viene fornita in \ref{hpfilter}.
\begin{lstlisting}[style=Matlab-editor,frame=single, caption=hpfilter, label=hpfilter]  % Start your code-block
function Hd = hpfilter
% All frequency values are in Hz.
Fs = 64;  % Sampling Frequency

Fstop = 0.4;    % Stopband Frequency
Fpass = 0.8;       % Passband Frequency
Astop = 60;      % Stopband Attenuation (dB)
Apass = 1;       % Passband Ripple (dB)
match = 'passband';  % Band to match exactly

% Construct an FDESIGN object and call its ELLIP method.
h  = fdesign.highpass(Fstop, Fpass, Astop, Apass, Fs);
Hd = design(h, 'cheby2', 'MatchExactly', match);
\end{lstlisting}
\subsection{Definizione degli intervalli}
Una volta filtrati i dati, il passo successivo dell'algoritmo consiste nel dividerli in intervalli temporali, al fine di poter computare le caratteristiche degli stessi. Un intervallo contiene un determinato movimento, che però verrebbe "interrotto" con la fine della finestra stessa e quindi potrei perdere informazioni su tale movimento. Per evitare il più possibile tale perdita, è usato usato un approccio che sfrutta le sovrapposizioni tra intervalli, per cui ogni nuova finestra non inizia subito dopo la fine della precedente, ma all'interno di essa. La durata degli intervalli che sono stati presi in considerazione sono:
\begin{itemize}
	\item  Da 1 secondi a 5 secondi per la finestra temporale, con un incremento di 0.5 secondi;
	\item Da 0.5 a 4.5 secondi per l'intervallo di overlap, con un incremento sempre di 0.5 secondi.
\end{itemize}
La condizione fondamentale per usare le sovrapposizioni è che l'intervallo delle stesse non sia mai maggiore della durata delle finestre temporali, per cui è stata posta la condizione che la finestra temporale sia sempre almeno 0.5 secondi più lunga dell'intervallo di sovrapposizione. Per capire da dove parte la nuova finestra, quindi, prendiamo la posizione a cui siamo arrivati e togliamo la durata della sovrapposizione. L'implementazione viene fornita in \ref{intervals}.
\begin{lstlisting}[style=Matlab-editor,frame=single, caption=Definizione degli intervalli, label=intervals]  % Start your code-block
...
for k = 5:5:45

Y = k/10;

for i = (Y+0.5):0.5:5
%dimensione della finestra in secondi
size_windows_sec = i;
%dimensione della finestra in campioni
size_windows_sample = Fs * i;

%dimensione dell'overlap in secondi
size_overlap_sec = Y;
%dimensione dell'overlap in campioni
size_overlap_samples = Fs * Y;

number_sample = 1;

%for each sample window, compute the features
for i=1:size_windows_sample-size_overlap_samples:m - size_windows_sample
B = A(i:i+size_windows_sample-1,:);
...
\end{lstlisting}
\subsection{Calcolo delle Feature}
 Per ogni possibile combinazione di finestra temporale e sovrapposizione, a questo punto vengono calcolate le feature per ogni intervallo. Le feature prese in considerazione nel nostro studio sono descritte in tabella \ref{TAB:Feature}.
\begin{table}[h!]
	\begin{tabular}{ |p{0.05\textwidth} | p{0.25\textwidth} | p{0.6\textwidth} | }
		\multicolumn{1}{|p{0.05\textwidth} |}{\textbf{N}} &  
		\multicolumn{1}{p{0.25\textwidth} |}{\textbf{Feature}} &
		\multicolumn{1}{p{0.6\textwidth} |}{\textbf{Descrizione}}\\
		\hline
		\hline
		1 & Minimo & Valore minimo del segnale\\
		2 & Massimo & Valore massimo del segnale \\
		3 & Mediana & Valore mediano del segnale \\
		4 & Media & Valore medio del segnale \\
		5 & Media Armonica & Media armonica del segnale \\
		6 & Errore Quadratico Medio & Valore Quadratico medio del segnale \\
		7 & Media Geometrica & Media geometrica del segnale \\
		8 & Varianza & Radice della deviazione standard \\
		9 & Deviazione Standard & Deviazione media del segnale rispetto alla media \\
		10 & Curtosi & Allontanamento dalla normalità distributiva del segnale \\
		11 & Simmetria & Grado di asimmetria della distribuzione del segnale \\
		12 & Moda & Il numero che appare più volte nel segnale \\
		13 & Media Tagliata & Media tagliatadel segnale nella finestra \\
		14 & Entropia & Misura della di distruzione delle componenti in frequenza \\
		15 & Range & Differenza tra il valore minimo e massimo del segnale \\
		16 & Magnitudine & Somma della norma euclidea di tre assi normalizzato sulla lunghezza del segnale \\
		17 & Area Magnitudine & Accelerazione della magnitudine di tre assi normalizzato sulla lunghezza del segnale \\
		18 & Autovalori delle direzioni dominanti & Autovalori della matrice di covarianza di tre assi \\
		19 & Accelerazione media dell'energia & Valore medio dell'energia sui 3 assi \\
	\end{tabular}
\caption{Descrizione delle Feature Statistiche}
\label{TAB:Feature}
\end{table}\\
Nel dataset, ogni campione è etichettato. Poiché le nostre feature sono composte da molti campioni messi assieme, si rende necessario trovare un metodo per unire, sbagliando il meno possibile, tutte le etichette della finestra che prendiamo in considerazione. Per fare ciò, si è deciso di utilizzare la funzione di moda, ossia il numero che si ripete più spesso all'intervallo dell'intervallo considerato. L'etichetta risultante viene inserita nella tabella e verrà utilizzata come criterio di confronto, al fine di valutare le prestazioni degli algoritmi di clustering. L'implementazione del codice è fornito in \ref{extract_feature}
\begin{lstlisting}[style=Matlab-editor,frame=single, caption=Calcolo delle Feature, label=extract_feature]  % Start your code-block
...
%time sample
F(number_sample, 1) = TIME(i,:);
%min --> minimum value for each accelerometer
F(number_sample, 2:10) = min(B);
%max --> maximum value for each accelerometer
F(number_sample, 11:19) = max(B);
%median --> median signal value
F(number_sample, 20:28) = median(B);
%mean --> average value
F(number_sample, 29:37) = mean(B);
%ArmMean --> harmonic average of the signal
F(number_sample, 38:46) = harmmean(B);
%root mean square --> quadratic mean value of the signal
F(number_sample, 47:55) = rms(B);
%variance --> square of the standard deviation
F(number_sample, 56:64) = var(B);
%standard deviation --> mean deviation of the signal compared to the
%average
F(number_sample, 65:73) = std(B);
%kurtosis --> degree of peakedness of the sensor signal distribution
%(allontanamento dalla normalita distributiva)
F(number_sample, 74:82) = kurtosis(B);
%skewdness --> degree of asymmetry of the sensor signal distribution
F(number_sample, 83:91) = skewness(B);
%mode --> number that appears most often in the signal
F(number_sample, 92:100) = mode(B);
%trim mean --> trimmed mean of the signal in the window
F(number_sample, 101:109) = trimmean(B,10);
%range --> difference between the largest and the smallest values of
%the signal
F(number_sample, 110:118) = range(B);
%signal magnitude vector --> sum of the euclidean norm over the three
%axis over the entire window normalized by the windows lenght
F(number_sample, 119) = svmn(B(:,1:3), length(B));
F(number_sample, 120) = svmn(B(:,4:6), length(B));
F(number_sample, 121) = svmn(B(:,7:9), length(B));
%normalized signal magnitude area --> acceleration magnitude summed
%over three axes normalized by the windows length
F(number_sample, 122) = sman(B(:,1:3), length(B));
F(number_sample, 123) = sman(B(:,4:6), length(B));
F(number_sample, 124) = sman(B(:,7:9), length(B));
%eigenvalues of dominant directions --> eigenvalues of the
%covariance matrix of the acceleration data along x, y and z axis
F(number_sample,125) = eigs(cov(B(:,1:3)),1);
F(number_sample,126) = eigs(cov(B(:,4:6)),1);
F(number_sample,127) = eigs(cov(B(:,7:9)),1);
%averaged acceleration energy --> mean value of the energy over
%three acceleration axes
F(number_sample,128) = energyn(B(:,1:3),length(B));
F(number_sample,129) = energyn(B(:,4:6),length(B));
F(number_sample,130) = energyn(B(:,7:9),length(B));
%is freezing?
F(number_sample,131) = mode(FREEZE(i:i+size_windows_sample-1,:));

%go to next sample
number_sample = number_sample + 1;
...
\end{lstlisting}
\subsection{Clustering}
Avendo il nuovo dataset composto dalle caratteristiche dei dati originali scomposti in intervalli, si possono applicare gli algoritmi di clustering. Quelli che sono stati presi in considerazione nella nostra analisi sono: K-means, Fuzzy C-Means e Neural Network. Il K-means viene testato in 4 varianti diverse, in base alle seguenti metriche di distanza: cityblock, correlation, cosine, euclidean.\\
Ogni algoritmo di clustering viene applicato in tutte le possibili combinazioni di intervalli ed ognuno di essi restituisce un vettore di numeri, che corrispondono alle etichette che assegnano ad ogni vettore di feature. Questi vengono salvati e verranno poi utilizzati per calcolare le prestazioni degli algoritmi stessi in confronto alla classificazione originale del dottore. L'implementazione del codice è fornita in \ref{clustering}
\begin{lstlisting}[style=Matlab-editor,frame=single, caption=Uso degli algoritmi di clustering, label=clustering]  % Start your code-block
...
            %% k-means %%%

% choose of parameter
means1 = 'sqeuclidean';
means2 = 'correlation';
means3 = 'cityblock';
means4 = 'cosine';
for q=1:4
if q == 1
dist_k = means1;
end
if q == 2
dist_k = means2;
end
if q == 3
dist_k = means3;
end
if q == 4
dist_k = means4;
end
options_km = statset('UseParallel', false);
maxiter = 100000;
% cluster
kidx = kmeans(bonds, numClust, 'distance', dist_k, 'options', options_km, 'MaxIter', maxiter);

P = array2table([A(:,n) kidx]);
writetable(P, [datadir 'versus_kmeans_' dist_k '_' fileruns(r).name] );
display([datadir 'versus_kmeans_' dist_k '_' fileruns(r).name]);
end

%%% neural networks - Self organizing Maps %%%

% Create a Self-Organizing Map
dimension1 = 3;
dimension2 = 1;
net = selforgmap([dimension1 dimension2]);

% Train the network
net.trainParam.showWindow = 0;
[net,tr] = train(net,bonds');

% Test the network
nidx = net(bonds');
nidx = vec2ind(nidx)';

P = array2table([A(:,n) nidx]);
writetable(P, [datadir 'versus_net_' fileruns(r).name] );
display([datadir 'versus_net_' fileruns(r).name]);


%     %%% FUZZY C-MEANS %%%
options(1) = 2;
options(2) = 10000;
options(3) = 1e-5;
options(4) = 0;
% Hide iteration information by passing appropriate options to FCM
[centres,U] = fcm(bonds,numClust,options);
[~, fidx] = max(U);
fidx = fidx';


P = array2table([A(:,n) fidx]);
writetable(P, [datadir 'versus_cmeans_' fileruns(r).name] );
display([datadir 'versus_cmeans_' fileruns(r).name]);
...
\end{lstlisting}
\subsection{Calcolo delle prestazioni}


%Per ogni combinazione di finestra temporale, quindi, vengono calcolate le rispettive feature e si procede ad applicare l'algoritmo di clustering. Quelli che sono stati scelti, in quanto più diffusi nel contesto di clustering, sono: k-means, self-organizing map e fuzzy c-means. Il k-means viene testato con tutte le sue metriche di distanza, per evidenziare eventuali differenze e decidere quale tra le 4 presenti (cosine, euclidean, cityblock, correlation) si adatta di più al nostro problema. Il fuzzy c-means è stato scelto anche perché è di soft clustering, ossia 2 punti potrebbero appartenere a 2 cluster diversi, il che ritorna utile nel trovare correttamente la terza label, in quanto nel dataset originale era etichettata con una diversa label.\\
%Ogni algoritmo di clustering restituisce un vettore di etichette, che indicano il numero di cluster a cui è stato assegnato ogni punto. Questi vengono messi a confronto con le true label, ossia le etichette inserite a mano dal dottore, e si calcolano le metriche di accuratezza, precisione, sensitività e F1-measure attraverso la matrice di confusione descritta precedentemente. Le true label vengono calcolate, per ogni vettore di feature, come la moda tra le label della finestra temporale, ossia come l'etichetta che si presente più volte all'interno della finestra stessa. Una volta ottenute le misure per tutti i campioni temporali, si cercano gli intervalli con il maggiore punteggio, dove con quest'ultimo intendiamo la media delle 4 grandezze calcolate. Nel nostro caso, come si vede nella figura \ref{SecondiOverlap}, abbiamo che i punteggi migliori vengono raggiunti nell'intervallo compreso tra 1.5 e 2 secondi, con una sovrapposizione di 0.5 o 1 secondo. Dato che nella maggior parte dei casi risultano tali intervalli, decidiamo di concentrarci su questi, anche perché sono accettabili in un'implementazione online. Nella figura \ref{Accuratezza} si può vedere il valore di accuratezza per ogni paziente per i vari algoritmi di clustering, mentre nella figura \ref{Precisione} possiamo osservare la precisione per ogni paziente ed infine nella figura \ref{Recall} si può vedere il valore di recall per ogni algortimo e paziente.
%\begin{figure}[]
%	\centering
%	\includegraphics[scale=0.35]{images/secondi_overlap.png}
%	\caption{Grafico degli intervalli di overlap e secondi della finestra temporale per ogni paziente}
%	\label{SecondiOverlap}
%\end{figure}
%
%\begin{figure}[]
%	\centering
%	\includegraphics[scale=0.35]{images/accuratezza.png}
%	\caption{Grafico dell'accuratezza per ogni paziente}
%	\label{Accuratezza}
%\end{figure}
%\begin{figure}[]
%	\centering
%	\includegraphics[scale=0.3]{images/precisione.png}
%	\caption{Grafico della precisione media delle classi per ogni paziente}
%	\label{Precisione}
%\end{figure}
%\begin{figure}[]
%	\centering
%	\includegraphics[scale=0.35]{images/recall.png}
%	\caption{Grafico della recall media delle classi per ogni paziente}
%	\label{Recall}
%\end{figure}
%Oltre a determinare le migliori combinazioni secondi-overlap, siamo stati in grado di verificare quale metrica dell'algoritmo di clustering k-means meglio si adatta ai nostri dati. Infatti, nella figura \ref{Accuratezza} possiamo vedere che la metrica Euclidean ha in media il valore più alto rispetto alle altre, anche se questo, osservando le figure \ref{Precisione} e \ref{Recall}, è dato dal fatto che sbaglia meno volte rispetto alle altre metriche ad etichettare il NoFog e, essendo questa label in quantità maggiore rispetto alle altre, porta ad un'accuracy totale più alta.\\

\section{Feature Dinamiche}


\section{Linear Discriminant Analysis}












%\begin{table}[htp]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & CMEANS &  &  &  \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,92 & 0,31 & 0,33 & 0,32 \\
%		& 1 & 2,50 & 0,00 & 0,00 \\
%		S02 & 0,44 & 0,46 & 0,63 & 0,53 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S03 & 0,70 & 0,51 & 0,57 & 0,54 \\
%		& 1 & 2 & 0,00 & 0,00 \\
%		S04 & 0,70 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 2 & 0,00 & 0,00 \\
%		S05 & 0,53 & 0,49 & 0,46 & 0,47 \\
%		& 0,50 & 1,50 & 0,00 & 0,00 \\
%		S06 & 0,57 & 0,36 & 0,32 & 0,34 \\
%		& 1,00 & 1,50 & 0,00 & 0,00 \\
%		S07 & 0,48 & 0,37 & 0,43 & 0,40 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S08 & 0,41 & 0,39 & 0,43 & 0,41 \\
%		& 1,50 & 2,50 & 0,00 & 0,00 \\
%		S09 & 0,59 & 0,35 & 0,37 & 0,36 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S10 & 0,73 & 0,33 & 0,00 & 0,00 \\
%		& 1 & 2 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering C-means}
%	\label{ratecmeans}
%\end{table}
%\begin{table}[htp]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & \multicolumn{4}{c}{KMEANS-CITYBLOCK} \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,32 & 0,33 & 0,24 & 0,28 \\
%		& 1,00 & 2,50 & 0,00 & 0,00 \\
%		S02 & 0,61 & 0,54 & 0,49 & 0,51 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S03 & 0,77 & 0,79 & 0,57 & 0,66 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S04 & 0,68 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 1,00 & 0,00 & 0,00 \\
%		S05 & 0,59 & 0,54 & 0,57 & 0,55 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S06 & 0,30 & 0,36 & 0,41 & 0,38 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S07 & 0,33 & 0,35 & 0,41 & 0,38 \\
%		& 1,50 & 2,50 & 0,00 & 0,00 \\
%		S08 & 0,31 & 0,40 & 0,39 & 0,40 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S09 & 0,54 & 0,37 & 0,39 & 0,38 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S10 & 0,29 & 0,33 & 0,00 & 0,00 \\
%		& 1,00 & 2,00 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering K-means con metrica di distanza Cityblock}
%	\label{ratekmeanscityblock}
%\end{table}
%\begin{table}[]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & \multicolumn{4}{c}{KMEANS-CORRELATION}  \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,47 & 0,36 & 0,48 & 0,41 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S02 & 0,45 & 0,57 & 0,67 & 0,62 \\
%		& 1,00 & 2,50 & 0,00 & 0,00 \\
%		S03 & 0,68 & 0,50 & 0,58 & 0,54 \\
%		& 1,00 & 2,50 & 0,00 & 0,00 \\
%		S04 & 0,62 & 0,33 & 0,00 & 0,00 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S05 & 0,28 & 0,30 & 0,32 & 0,31 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S06 & 0,52 & 0,44 & 0,44 & 0,44 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S07 & 0,54 & 0,35 & 0,35 & 0,35 \\
%		& 1,50 & 2,50 & 0,00 & 0,00 \\
%		S08 & 0,53 & 0,38 & 0,40 & 0,39 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S09 & 0,53 & 0,50 & 0,58 & 0,54 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S10 & 0,18 & 0,33 & 0,00 & 0,00 \\
%		& 1,00 & 2,50 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering K-means con metrica di distanza Correlation}
%	\label{ratekmeanscorrelation}
%\end{table}
%\begin{table}[]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & \multicolumn{4}{c}{KMEANS-COSINE} \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,47 & 0,31 & 0,23 & 0,27 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S02 & 0,79 & 0,36 & 0,35 & 0,35 \\
%		& 0,50 & 1,50 & 0,00 & 0,00 \\
%		S03 & 0,76 & 0,46 & 0,55 & 0,50 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S04 & 0,61 & 0,33 & 0,00 & 0,00 \\
%		& 1,00 & 1,50 & 0,00 & 0,00 \\
%		S05 & 0,28 & 0,30 & 0,32 & 0,31 \\
%		& 1,00 & 2,50 & 0,00 & 0,00 \\
%		S06 & 0,51 & 0,41 & 0,38 & 0,40 \\
%		& 0,50 & 1,50 & 0,00 & 0,00 \\
%		S07 & 0,36 & 0,34 & 0,40 & 0,37 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S08 & 0,67 & 0,36 & 0,35 & 0,35 \\
%		& 1,00 & 1,50 & 0,00 & 0,00 \\
%		S09 & 0,54 & 0,51 & 0,60 & 0,55 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S10 & 0,18 & 0,33 & 0,00 & 0,00 \\
%		& 2,00 & 2,50 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering K-means con metrica di distanza Cosine}
%	\label{ratekmeanscosine}
%\end{table}
%\begin{table}[]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & \multicolumn{4}{c}{KMEANS-EUCLIDEAN} \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,92 & 0,72 & 0,34 & 0,46 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S02 & 0,82 & 0,61 & 0,34 & 0,44 \\
%		& 0,50 & 2,50 & 0,00 & 0,00 \\
%		S03 & 0,75 & 0,78 & 0,54 & 0,64 \\
%		& 1,50 & 2,50 & 0,00 & 0,00 \\
%		S04 & 1,00 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S05 & 0,67 & 0,56 & 0,33 & 0,42 \\
%		& 1,00 & 2,00 & 0,00 & 0,00 \\
%		S06 & 0,91 & 0,30 & 0,33 & 0,32 \\
%		& 1,00 & 1,50 & 0,00 & 0,00 \\
%		S07 & 0,92 & 0,31 & 0,33 & 0,32 \\
%		& 2,00 & 2,50 & 0,00 & 0,00 \\
%		S08 & 0,70 & 0,57 & 0,34 & 0,42 \\
%		& 0,50 & 1,00 & 0,00 & 0,00 \\
%		S09 & 0,81 & 0,60 & 0,34 & 0,43 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S10 & 1,00 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 2,00 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering K-means con metrica di distanza Euclidean}
%	\label{ratekmeanseuclidean}
%\end{table}
%\begin{table}[]
%	\centering
%	\begin{tabular}{lllll}
%		Tutti & \multicolumn{4}{c}{NEURAL NETWORK} \\
%		Paziente & Accuratezza & Precisione & Recall & F1-measure \\
%		S01 & 0,92 & 0,31 & 0,33 & 0,32 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S02 & 0,81 & 0,44 & 0,34 & 0,38 \\
%		& 0,50 & 1,50 & 0,00 & 0,00 \\
%		S03 & 0,75 & 0,78 & 0,54 & 0,63 \\
%		& 0,50 & 2,50 & 0,00 & 0,00 \\
%		S04 & 0,64 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S05 & 0,58 & 0,42 & 0,46 & 0,44 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S06 & 0,57 & 0,32 & 0,31 & 0,31 \\
%		& 1,00 & 1,50 & 0,00 & 0,00 \\
%		S07 & 0,63 & 0,30 & 0,26 & 0,28 \\
%		& 2,00 & 2,50 & 0,00 & 0,00 \\
%		S08 & 0,56 & 0,69 & 0,38 & 0,49 \\
%		& 1,50 & 2,00 & 0,00 & 0,00 \\
%		S09 & 0,57 & 0,37 & 0,41 & 0,39 \\
%		& 0,50 & 2,00 & 0,00 & 0,00 \\
%		S10 & 1,00 & 0,33 & 0,00 & 0,00 \\
%		& 0,50 & 1,00 & 0,00 & 0,00
%	\end{tabular}
%	\caption{Rate Pazienti per l'algoritmo di clustering Self-Organizing Map}
%	\label{rateneuralnetwork}
%\end{table}